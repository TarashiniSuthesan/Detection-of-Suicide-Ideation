{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling1D, Dropout, Conv1D, Input, LSTM, Bidirectional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined-selftext.csv')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_join(df, sep, *cols):\n",
    "   ...:     from functools import reduce\n",
    "   ...:     return reduce(lambda x, y: x.astype(str).str.cat(y.astype(str), sep=sep), \n",
    "   ...:                   [df[col] for col in cols])\n",
    "   ...: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = str_join(df,\" \", 'title', 'usertext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = str_join(df,\" \", 'title', 'usertext')\n",
    "del df['title']\n",
    "del df['usertext']\n",
    "df.rename(columns = {'y':'is_suicide'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].apply(lambda x: gensim.utils.simple_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text_clean'], df['is_suicide'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(df['text_clean'],\n",
    "                                   vector_size=300,\n",
    "                                   epochs=20,\n",
    "                                   window=10,\n",
    "                                   min_count=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a03581770919>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
      "<ipython-input-9-a03581770919>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n"
     ]
    }
   ],
   "source": [
    "words = set(w2v_model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_train])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(300, dtype=float))\n",
    "        \n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(300, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect_avg = np.array(X_train_vect_avg)\n",
    "X_test_vect_avg = np.array(X_test_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 300) (375, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vect_avg.shape, X_test_vect_avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498,) (375,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 300, 100)          40800     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 150, 100)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                960064    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,000,929\n",
      "Trainable params: 1,000,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "\n",
    "model10 = keras.Sequential()\n",
    "model10.add(keras.layers.Input(shape=(300, 1)))\n",
    "model10.add(keras.layers.LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "model10.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model10.add(keras.layers.Flatten())\n",
    "model10.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model10.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model10.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 11s 211ms/step - loss: 0.6755 - accuracy: 0.5935 - precision_1: 0.5994 - recall_1: 0.6693 - f1_score: 0.6864 - val_loss: 0.6433 - val_accuracy: 0.6233 - val_precision_1: 0.5988 - val_recall_1: 0.6849 - val_f1_score: 0.6547\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 7s 178ms/step - loss: 0.6471 - accuracy: 0.6361 - precision_1: 0.6389 - recall_1: 0.6981 - f1_score: 0.6864 - val_loss: 0.6312 - val_accuracy: 0.6433 - val_precision_1: 0.6309 - val_recall_1: 0.6438 - val_f1_score: 0.6547\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 7s 182ms/step - loss: 0.6331 - accuracy: 0.6369 - precision_1: 0.6347 - recall_1: 0.7188 - f1_score: 0.6864 - val_loss: 0.6170 - val_accuracy: 0.6300 - val_precision_1: 0.6159 - val_recall_1: 0.6370 - val_f1_score: 0.6547\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 7s 196ms/step - loss: 0.6359 - accuracy: 0.6511 - precision_1: 0.6529 - recall_1: 0.7093 - f1_score: 0.6864 - val_loss: 0.6218 - val_accuracy: 0.6300 - val_precision_1: 0.6636 - val_recall_1: 0.4863 - val_f1_score: 0.6547\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 8s 199ms/step - loss: 0.6210 - accuracy: 0.6594 - precision_1: 0.6741 - recall_1: 0.6741 - f1_score: 0.6864 - val_loss: 0.6224 - val_accuracy: 0.6333 - val_precision_1: 0.6059 - val_recall_1: 0.7055 - val_f1_score: 0.6547\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 0.6204 - accuracy: 0.6494 - precision_1: 0.6399 - recall_1: 0.7524 - f1_score: 0.6864 - val_loss: 0.6152 - val_accuracy: 0.6367 - val_precision_1: 0.6108 - val_recall_1: 0.6986 - val_f1_score: 0.6547\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 8s 201ms/step - loss: 0.6274 - accuracy: 0.6436 - precision_1: 0.6423 - recall_1: 0.7173 - f1_score: 0.6864 - val_loss: 0.6091 - val_accuracy: 0.6400 - val_precision_1: 0.6250 - val_recall_1: 0.6507 - val_f1_score: 0.6547\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 0.6133 - accuracy: 0.6661 - precision_1: 0.6697 - recall_1: 0.7125 - f1_score: 0.6864 - val_loss: 0.6123 - val_accuracy: 0.6467 - val_precision_1: 0.6370 - val_recall_1: 0.6370 - val_f1_score: 0.6547\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 8s 201ms/step - loss: 0.6216 - accuracy: 0.6678 - precision_1: 0.6738 - recall_1: 0.7061 - f1_score: 0.6864 - val_loss: 0.6096 - val_accuracy: 0.6467 - val_precision_1: 0.6389 - val_recall_1: 0.6301 - val_f1_score: 0.6547\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 0.6087 - accuracy: 0.6828 - precision_1: 0.6804 - recall_1: 0.7412 - f1_score: 0.6864 - val_loss: 0.6103 - val_accuracy: 0.6467 - val_precision_1: 0.6351 - val_recall_1: 0.6438 - val_f1_score: 0.6547\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.5877 - accuracy: 0.7067 - precision_1: 0.7442 - recall_1: 0.6598 - f1_score: 0.6819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5877171754837036,\n",
       " 0.7066666483879089,\n",
       " 0.7441860437393188,\n",
       " 0.6597937941551208,\n",
       " array([0.6818981], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history11 = model10.fit(\n",
    "    X_train_vect_avg, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model10.evaluate(X_test_vect_avg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 300, 200)         81600     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 150, 200)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 30000)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                1920064   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,001,729\n",
      "Trainable params: 2,001,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM\n",
    "\n",
    "model3 = keras.Sequential()\n",
    "\n",
    "model3.add(keras.layers.Input(shape=(300, 1)))\n",
    "model3.add(keras.layers.Bidirectional(LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)))\n",
    "model3.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model3.add(keras.layers.Flatten())\n",
    "model3.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 22s 453ms/step - loss: 0.6711 - accuracy: 0.5885 - precision_8: 0.5868 - recall_8: 0.6882 - f1_score: 0.6813 - val_loss: 0.6513 - val_accuracy: 0.6000 - val_precision_8: 0.6043 - val_recall_8: 0.5638 - val_f1_score: 0.6637\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 17s 459ms/step - loss: 0.6350 - accuracy: 0.6427 - precision_8: 0.6605 - recall_8: 0.6349 - f1_score: 0.6813 - val_loss: 0.6258 - val_accuracy: 0.6733 - val_precision_8: 0.6474 - val_recall_8: 0.7517 - val_f1_score: 0.6637\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 19s 498ms/step - loss: 0.6275 - accuracy: 0.6477 - precision_8: 0.6495 - recall_8: 0.6914 - f1_score: 0.6813 - val_loss: 0.6258 - val_accuracy: 0.6333 - val_precision_8: 0.6757 - val_recall_8: 0.5034 - val_f1_score: 0.6637\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 19s 501ms/step - loss: 0.6177 - accuracy: 0.6653 - precision_8: 0.6730 - recall_8: 0.6850 - f1_score: 0.6813 - val_loss: 0.6149 - val_accuracy: 0.6833 - val_precision_8: 0.6753 - val_recall_8: 0.6980 - val_f1_score: 0.6637\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 20s 518ms/step - loss: 0.6125 - accuracy: 0.6694 - precision_8: 0.6778 - recall_8: 0.6866 - f1_score: 0.6813 - val_loss: 0.6166 - val_accuracy: 0.6567 - val_precision_8: 0.6337 - val_recall_8: 0.7315 - val_f1_score: 0.6637\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 20s 526ms/step - loss: 0.6139 - accuracy: 0.6519 - precision_8: 0.6695 - recall_8: 0.6446 - f1_score: 0.6813 - val_loss: 0.6202 - val_accuracy: 0.6433 - val_precision_8: 0.6721 - val_recall_8: 0.5503 - val_f1_score: 0.6637\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 20s 524ms/step - loss: 0.6130 - accuracy: 0.6519 - precision_8: 0.6689 - recall_8: 0.6462 - f1_score: 0.6813 - val_loss: 0.6171 - val_accuracy: 0.6733 - val_precision_8: 0.6393 - val_recall_8: 0.7852 - val_f1_score: 0.6637\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 20s 534ms/step - loss: 0.6138 - accuracy: 0.6686 - precision_8: 0.6677 - recall_8: 0.7141 - f1_score: 0.6813 - val_loss: 0.6220 - val_accuracy: 0.6633 - val_precision_8: 0.6200 - val_recall_8: 0.8322 - val_f1_score: 0.6637\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 20s 533ms/step - loss: 0.5995 - accuracy: 0.6820 - precision_8: 0.6919 - recall_8: 0.6931 - f1_score: 0.6813 - val_loss: 0.6158 - val_accuracy: 0.6800 - val_precision_8: 0.6373 - val_recall_8: 0.8255 - val_f1_score: 0.6637\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 20s 526ms/step - loss: 0.6033 - accuracy: 0.6728 - precision_8: 0.6765 - recall_8: 0.7027 - f1_score: 0.6813 - val_loss: 0.6051 - val_accuracy: 0.6833 - val_precision_8: 0.6627 - val_recall_8: 0.7383 - val_f1_score: 0.6637\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.6050 - accuracy: 0.6613 - precision_8: 0.6766 - recall_8: 0.6869 - f1_score: 0.6911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6050381064414978,\n",
       " 0.6613333225250244,\n",
       " 0.676616907119751,\n",
       " 0.6868686676025391,\n",
       " array([0.69109946], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history3 = model3.fit(\n",
    "    X_train_vect_avg, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model3.evaluate(X_test_vect_avg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 300, 100)          40800     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 300, 5)            1005      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 150, 5)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 750)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                48064     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,934\n",
      "Trainable params: 89,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM + CNN\n",
    "\n",
    "model10 = keras.Sequential()\n",
    "\n",
    "model10.add(keras.layers.Input(shape=(300, 1)))\n",
    "model10.add(keras.layers.LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "model10.add(keras.layers.Conv1D(5, (2,), padding='same', activation='relu'))\n",
    "model10.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model10.add(keras.layers.Flatten())\n",
    "model10.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model10.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model10.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 11s 225ms/step - loss: 0.6926 - accuracy: 0.5109 - precision_5: 0.5183 - recall_5: 0.7561 - f1_score: 0.6813 - val_loss: 0.6921 - val_accuracy: 0.4967 - val_precision_5: 0.4967 - val_recall_5: 1.0000 - val_f1_score: 0.6637\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 8s 217ms/step - loss: 0.6878 - accuracy: 0.5159 - precision_5: 0.5163 - recall_5: 0.9984 - f1_score: 0.6813 - val_loss: 0.6876 - val_accuracy: 0.5667 - val_precision_5: 0.5367 - val_recall_5: 0.9329 - val_f1_score: 0.6637\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 9s 244ms/step - loss: 0.6799 - accuracy: 0.5534 - precision_5: 0.5393 - recall_5: 0.9305 - f1_score: 0.6813 - val_loss: 0.6810 - val_accuracy: 0.5733 - val_precision_5: 0.5399 - val_recall_5: 0.9530 - val_f1_score: 0.6637\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 10s 267ms/step - loss: 0.6680 - accuracy: 0.5952 - precision_5: 0.6003 - recall_5: 0.6478 - f1_score: 0.6813 - val_loss: 0.7826 - val_accuracy: 0.4967 - val_precision_5: 0.4967 - val_recall_5: 1.0000 - val_f1_score: 0.6637\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 10s 264ms/step - loss: 0.6856 - accuracy: 0.5710 - precision_5: 0.5710 - recall_5: 0.6817 - f1_score: 0.6813 - val_loss: 0.6619 - val_accuracy: 0.6167 - val_precision_5: 0.5977 - val_recall_5: 0.6980 - val_f1_score: 0.6637\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 10s 275ms/step - loss: 0.6556 - accuracy: 0.6227 - precision_5: 0.6174 - recall_5: 0.7092 - f1_score: 0.6813 - val_loss: 0.6506 - val_accuracy: 0.6333 - val_precision_5: 0.6077 - val_recall_5: 0.7383 - val_f1_score: 0.6637\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 11s 278ms/step - loss: 0.6482 - accuracy: 0.6436 - precision_5: 0.6500 - recall_5: 0.6721 - f1_score: 0.6813 - val_loss: 0.6527 - val_accuracy: 0.6267 - val_precision_5: 0.6095 - val_recall_5: 0.6913 - val_f1_score: 0.6637\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 10s 264ms/step - loss: 0.6561 - accuracy: 0.6210 - precision_5: 0.6350 - recall_5: 0.6268 - f1_score: 0.6813 - val_loss: 0.6480 - val_accuracy: 0.6233 - val_precision_5: 0.6071 - val_recall_5: 0.6846 - val_f1_score: 0.6637\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 10s 270ms/step - loss: 0.6467 - accuracy: 0.6144 - precision_5: 0.6210 - recall_5: 0.6511 - f1_score: 0.6813 - val_loss: 0.6466 - val_accuracy: 0.6333 - val_precision_5: 0.6154 - val_recall_5: 0.6980 - val_f1_score: 0.6637\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 10s 265ms/step - loss: 0.6447 - accuracy: 0.6285 - precision_5: 0.6605 - recall_5: 0.5784 - f1_score: 0.6813 - val_loss: 0.6571 - val_accuracy: 0.6267 - val_precision_5: 0.5869 - val_recall_5: 0.8389 - val_f1_score: 0.6637\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.6666 - accuracy: 0.6240 - precision_5: 0.6059 - recall_5: 0.8232 - f1_score: 0.6911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6665661334991455,\n",
       " 0.6240000128746033,\n",
       " 0.6059479713439941,\n",
       " 0.8232323527336121,\n",
       " array([0.69109946], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history10 = model10.fit(\n",
    "    X_train_vect_avg, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model10.evaluate(X_test_vect_avg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirectio  (None, 300, 200)         81600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 300, 5)            2005      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 150, 5)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 750)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                48064     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,734\n",
      "Trainable params: 131,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM + CNN\n",
    "\n",
    "model6 = keras.Sequential()\n",
    "\n",
    "model6.add(keras.layers.Input(shape=(300, 1)))\n",
    "model6.add(keras.layers.Bidirectional(LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)))\n",
    "model6.add(keras.layers.Conv1D(5, (2,), padding='same', activation='relu'))\n",
    "model6.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model6.add(keras.layers.Flatten())\n",
    "model6.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model6.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model6.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 24s 502ms/step - loss: 0.6904 - accuracy: 0.5267 - precision_9: 0.5323 - recall_9: 0.6914 - f1_score: 0.6813 - val_loss: 0.6825 - val_accuracy: 0.5600 - val_precision_9: 0.5431 - val_recall_9: 0.7181 - val_f1_score: 0.6637\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 19s 511ms/step - loss: 0.6676 - accuracy: 0.6002 - precision_9: 0.5967 - recall_9: 0.6979 - f1_score: 0.6813 - val_loss: 0.6717 - val_accuracy: 0.5833 - val_precision_9: 0.5526 - val_recall_9: 0.8456 - val_f1_score: 0.6637\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 21s 543ms/step - loss: 0.6606 - accuracy: 0.6252 - precision_9: 0.6197 - recall_9: 0.7108 - f1_score: 0.6813 - val_loss: 0.6475 - val_accuracy: 0.6267 - val_precision_9: 0.6209 - val_recall_9: 0.6376 - val_f1_score: 0.6637\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 21s 544ms/step - loss: 0.6433 - accuracy: 0.6244 - precision_9: 0.6528 - recall_9: 0.5832 - f1_score: 0.6813 - val_loss: 0.6506 - val_accuracy: 0.6200 - val_precision_9: 0.5814 - val_recall_9: 0.8389 - val_f1_score: 0.6637\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 21s 555ms/step - loss: 0.6381 - accuracy: 0.6336 - precision_9: 0.6389 - recall_9: 0.6688 - f1_score: 0.6813 - val_loss: 0.6320 - val_accuracy: 0.6433 - val_precision_9: 0.6419 - val_recall_9: 0.6376 - val_f1_score: 0.6637\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 21s 543ms/step - loss: 0.6209 - accuracy: 0.6494 - precision_9: 0.6572 - recall_9: 0.6721 - f1_score: 0.6813 - val_loss: 0.6278 - val_accuracy: 0.6367 - val_precision_9: 0.6176 - val_recall_9: 0.7047 - val_f1_score: 0.6637\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 21s 558ms/step - loss: 0.6223 - accuracy: 0.6503 - precision_9: 0.6695 - recall_9: 0.6381 - f1_score: 0.6813 - val_loss: 0.6262 - val_accuracy: 0.6567 - val_precision_9: 0.6353 - val_recall_9: 0.7248 - val_f1_score: 0.6637\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.6231 - accuracy: 0.6544 - precision_9: 0.6711 - recall_9: 0.6494 - f1_score: 0.6813 - val_loss: 0.6297 - val_accuracy: 0.6567 - val_precision_9: 0.6237 - val_recall_9: 0.7785 - val_f1_score: 0.6637\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 21s 551ms/step - loss: 0.6189 - accuracy: 0.6694 - precision_9: 0.6677 - recall_9: 0.7173 - f1_score: 0.6813 - val_loss: 0.6210 - val_accuracy: 0.6333 - val_precision_9: 0.6696 - val_recall_9: 0.5168 - val_f1_score: 0.6637\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 21s 563ms/step - loss: 0.6204 - accuracy: 0.6511 - precision_9: 0.6706 - recall_9: 0.6381 - f1_score: 0.6813 - val_loss: 0.6182 - val_accuracy: 0.6567 - val_precision_9: 0.6420 - val_recall_9: 0.6980 - val_f1_score: 0.6637\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.6271 - accuracy: 0.6640 - precision_9: 0.6800 - recall_9: 0.6869 - f1_score: 0.6911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6271308660507202,\n",
       " 0.6639999747276306,\n",
       " 0.6800000071525574,\n",
       " 0.6868686676025391,\n",
       " array([0.69109946], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history11 = model6.fit(\n",
    "    X_train_vect_avg, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model6.evaluate(X_test_vect_avg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
