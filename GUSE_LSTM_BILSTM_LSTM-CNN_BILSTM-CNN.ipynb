{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined-selftext.csv')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_join(df, sep, *cols):\n",
    "   ...:     from functools import reduce\n",
    "   ...:     return reduce(lambda x, y: x.astype(str).str.cat(y.astype(str), sep=sep), \n",
    "   ...:                   [df[col] for col in cols])\n",
    "   ...: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = str_join(df,\" \", 'title', 'usertext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['title']\n",
    "del df['usertext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "STOPWORDS = STOPWORDS.union(set(['im', 'ive', 'ill', 'wa', 'ha', 'aint', 'thats', 'la', 'le', 'please', 'feel', 'rly', 'u', 'nan', 'emptypost']))\n",
    "\n",
    "stop = STOPWORDS\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_suicide\"] = df[\"y\"].apply(lambda x: \"depressed\" if x < 1 else \"suicidal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "suicidal_reddits = df[df.is_suicide == \"suicidal\"]\n",
    "depressed_reddits = df[df.is_suicide == \"depressed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suicidal_df = suicidal_reddits.sample(n=len(depressed_reddits), random_state=RANDOM_SEED)\n",
    "suicidal_df = suicidal_reddits\n",
    "depressed_df = depressed_reddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddits_df = (pd.concat([suicidal_df, depressed_df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the \"tarfile\" module\n",
    "import tarfile\n",
    "\n",
    "# open file\n",
    "file = tarfile.open('universal-sentence-encoder-multilingual-large_3.tar.gz')\n",
    "\n",
    "# extracting file\n",
    "file.extractall(\"C:\\\\Users\\\\user\\\\SD\\\\GUSE\\GUSE3\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use = hub.load(\"C:\\\\Users\\\\user\\\\SD\\\\GUSE\\\\GUSE3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "type_one_hot = OneHotEncoder(sparse=False).fit_transform(\n",
    "  reddits_df.is_suicide.to_numpy().reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reddits, test_reddits, y_train, y_test =\\\n",
    "  train_test_split(\n",
    "    reddits_df.text, \n",
    "    type_one_hot, \n",
    "    test_size=.2, \n",
    "    random_state=RANDOM_SEED\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1498/1498 [01:33<00:00, 16.00it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "for r in tqdm(train_reddits):\n",
    "  emb = use(r)\n",
    "  reddit_emb = tf.reshape(emb, [-1]).numpy()\n",
    "  X_train.append(reddit_emb)\n",
    "\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:23<00:00, 16.00it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "for r in tqdm(test_reddits):\n",
    "  emb = use(r)\n",
    "  reddit_emb = tf.reshape(emb, [-1]).numpy()\n",
    "  X_test.append(reddit_emb)\n",
    "\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 512) (375, 512)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 2) (375, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling1D, Dropout, Conv1D, Input, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirectio  (None, 512, 200)         81600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 512, 5)            2005      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 256, 5)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,437\n",
      "Trainable params: 96,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM 100 + CNN\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(X_train.shape[1], 1)))\n",
    "model.add(keras.layers.Bidirectional(LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)))\n",
    "model.add(keras.layers.Conv1D(5, (2,), padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(keras.layers.Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(),\n",
    "                              metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=2)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.6929 - accuracy: 0.5150 - precision_3: 0.5183 - recall_3: 0.5317 - f1_score: 0.4030 - val_loss: 0.6949 - val_accuracy: 0.4867 - val_precision_3: 0.4867 - val_recall_3: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.6932 - accuracy: 0.5234 - precision_3: 0.5234 - recall_3: 0.5234 - f1_score: 0.3436 - val_loss: 0.6935 - val_accuracy: 0.4867 - val_precision_3: 0.4867 - val_recall_3: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6927 - accuracy: 0.5234 - precision_3: 0.5234 - recall_3: 0.5234 - f1_score: 0.3436 - val_loss: 0.6947 - val_accuracy: 0.4867 - val_precision_3: 0.4867 - val_recall_3: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.6923 - accuracy: 0.5234 - precision_3: 0.5234 - recall_3: 0.5234 - f1_score: 0.3436 - val_loss: 0.6953 - val_accuracy: 0.4867 - val_precision_3: 0.4867 - val_recall_3: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6923 - accuracy: 0.5234 - precision_3: 0.5234 - recall_3: 0.5234 - f1_score: 0.3436 - val_loss: 0.6948 - val_accuracy: 0.4867 - val_precision_3: 0.4867 - val_recall_3: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6914 - accuracy: 0.5234 - precision_3: 0.5246 - recall_3: 0.5259 - f1_score: 0.3436 - val_loss: 0.6923 - val_accuracy: 0.4867 - val_precision_3: 0.4867 - val_recall_3: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6907 - accuracy: 0.5234 - precision_3: 0.5256 - recall_3: 0.5309 - f1_score: 0.3436 - val_loss: 0.6901 - val_accuracy: 0.4867 - val_precision_3: 0.4850 - val_recall_3: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6869 - accuracy: 0.5234 - precision_3: 0.5314 - recall_3: 0.5376 - f1_score: 0.3436 - val_loss: 0.6819 - val_accuracy: 0.4867 - val_precision_3: 0.4950 - val_recall_3: 0.5000 - val_f1_score: 0.3274\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6745 - accuracy: 0.5234 - precision_3: 0.5403 - recall_3: 0.5651 - f1_score: 0.3467 - val_loss: 0.6664 - val_accuracy: 0.4867 - val_precision_3: 0.5063 - val_recall_3: 0.5367 - val_f1_score: 0.3274\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.6689 - accuracy: 0.5860 - precision_3: 0.5978 - recall_3: 0.5918 - f1_score: 0.5273 - val_loss: 0.6576 - val_accuracy: 0.6667 - val_precision_3: 0.5515 - val_recall_3: 0.8033 - val_f1_score: 0.6438\n",
      "12/12 [==============================] - 3s 216ms/step - loss: 0.6623 - accuracy: 0.6427 - precision_3: 0.5564 - recall_3: 0.8160 - f1_score: 0.6147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6622888445854187,\n",
       " 0.6426666378974915,\n",
       " 0.5563636422157288,\n",
       " 0.8159999847412109,\n",
       " array([0.51094896, 0.7184874 ], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model5.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model5.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirectio  (None, 512, 200)         81600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 256, 200)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 51200)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                512010    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 593,632\n",
      "Trainable params: 593,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM 100\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(X_train.shape[1], 1)))\n",
    "model.add(keras.layers.Bidirectional(LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(keras.layers.Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=2)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.6920 - accuracy: 0.5092 - precision_5: 0.4897 - recall_5: 0.6177 - f1_score: 0.3995 - val_loss: 0.6903 - val_accuracy: 0.4867 - val_precision_5: 0.4860 - val_recall_5: 0.9267 - val_f1_score: 0.3274\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6857 - accuracy: 0.5551 - precision_5: 0.5497 - recall_5: 0.5451 - f1_score: 0.5403 - val_loss: 0.6637 - val_accuracy: 0.5967 - val_precision_5: 0.5979 - val_recall_5: 0.7433 - val_f1_score: 0.5666\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6498 - accuracy: 0.6260 - precision_5: 0.6257 - recall_5: 0.6586 - f1_score: 0.6248 - val_loss: 0.6066 - val_accuracy: 0.6933 - val_precision_5: 0.6761 - val_recall_5: 0.7167 - val_f1_score: 0.6902\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6295 - accuracy: 0.6494 - precision_5: 0.6468 - recall_5: 0.6511 - f1_score: 0.6462 - val_loss: 0.6057 - val_accuracy: 0.6867 - val_precision_5: 0.6833 - val_recall_5: 0.6833 - val_f1_score: 0.6770\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.6154 - accuracy: 0.6586 - precision_5: 0.6628 - recall_5: 0.6644 - f1_score: 0.6567 - val_loss: 0.5757 - val_accuracy: 0.7233 - val_precision_5: 0.6855 - val_recall_5: 0.7700 - val_f1_score: 0.7228\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.6125 - accuracy: 0.6644 - precision_5: 0.6645 - recall_5: 0.6694 - f1_score: 0.6632 - val_loss: 0.5636 - val_accuracy: 0.7167 - val_precision_5: 0.7110 - val_recall_5: 0.7300 - val_f1_score: 0.7163\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.6011 - accuracy: 0.6828 - precision_5: 0.6836 - recall_5: 0.6836 - f1_score: 0.6809 - val_loss: 0.5511 - val_accuracy: 0.7167 - val_precision_5: 0.7089 - val_recall_5: 0.7467 - val_f1_score: 0.7160\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 49s 1s/step - loss: 0.6054 - accuracy: 0.6795 - precision_5: 0.6784 - recall_5: 0.6903 - f1_score: 0.6775 - val_loss: 0.5548 - val_accuracy: 0.7133 - val_precision_5: 0.7009 - val_recall_5: 0.7500 - val_f1_score: 0.7118\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.5772 - accuracy: 0.7137 - precision_5: 0.7118 - recall_5: 0.7237 - f1_score: 0.7122 - val_loss: 0.5546 - val_accuracy: 0.7367 - val_precision_5: 0.7450 - val_recall_5: 0.7400 - val_f1_score: 0.7338\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.5885 - accuracy: 0.6861 - precision_5: 0.6914 - recall_5: 0.6845 - f1_score: 0.6841 - val_loss: 0.5502 - val_accuracy: 0.7433 - val_precision_5: 0.7433 - val_recall_5: 0.7433 - val_f1_score: 0.7415\n",
      "12/12 [==============================] - 3s 212ms/step - loss: 0.5925 - accuracy: 0.6907 - precision_5: 0.6900 - recall_5: 0.6827 - f1_score: 0.6876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5925047397613525,\n",
       " 0.690666675567627,\n",
       " 0.6900269389152527,\n",
       " 0.6826666593551636,\n",
       " array([0.65680474, 0.7184467 ], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model5.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model5.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 512, 100)          40800     \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 512, 5)            1005      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 256, 5)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                12810     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,637\n",
      "Trainable params: 54,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM 100 + CNN\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling1D, Dropout, Conv1D, LSTM, Input\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(X_train.shape[1], 1)))\n",
    "model.add(keras.layers.LSTM(100, dropout=0.5, recurrent_dropout=0.5)))\n",
    "model.add(keras.layers.Conv1D(5, (2,), padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(keras.layers.Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), \n",
    "                              metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=2)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 22s 497ms/step - loss: 0.6927 - accuracy: 0.5167 - precision_7: 0.5165 - recall_7: 0.5225 - f1_score: 0.3809 - val_loss: 0.6946 - val_accuracy: 0.4867 - val_precision_7: 0.4867 - val_recall_7: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 19s 491ms/step - loss: 0.6928 - accuracy: 0.5234 - precision_7: 0.5234 - recall_7: 0.5234 - f1_score: 0.3436 - val_loss: 0.6928 - val_accuracy: 0.4867 - val_precision_7: 0.4867 - val_recall_7: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 19s 511ms/step - loss: 0.6919 - accuracy: 0.5234 - precision_7: 0.5234 - recall_7: 0.5234 - f1_score: 0.3436 - val_loss: 0.6927 - val_accuracy: 0.4867 - val_precision_7: 0.4867 - val_recall_7: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 19s 512ms/step - loss: 0.6895 - accuracy: 0.5234 - precision_7: 0.5242 - recall_7: 0.5250 - f1_score: 0.3436 - val_loss: 0.6893 - val_accuracy: 0.4867 - val_precision_7: 0.4867 - val_recall_7: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 19s 511ms/step - loss: 0.6836 - accuracy: 0.5234 - precision_7: 0.5230 - recall_7: 0.5225 - f1_score: 0.3436 - val_loss: 0.6806 - val_accuracy: 0.4867 - val_precision_7: 0.4901 - val_recall_7: 0.4933 - val_f1_score: 0.3274\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 20s 515ms/step - loss: 0.6774 - accuracy: 0.5442 - precision_7: 0.5399 - recall_7: 0.5876 - f1_score: 0.4072 - val_loss: 0.6692 - val_accuracy: 0.5900 - val_precision_7: 0.5850 - val_recall_7: 0.5967 - val_f1_score: 0.5194\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 20s 518ms/step - loss: 0.6691 - accuracy: 0.5785 - precision_7: 0.5768 - recall_7: 0.5893 - f1_score: 0.5074 - val_loss: 0.6590 - val_accuracy: 0.6800 - val_precision_7: 0.6775 - val_recall_7: 0.6933 - val_f1_score: 0.6667\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 19s 512ms/step - loss: 0.6661 - accuracy: 0.6127 - precision_7: 0.6173 - recall_7: 0.6085 - f1_score: 0.5833 - val_loss: 0.6493 - val_accuracy: 0.7000 - val_precision_7: 0.6931 - val_recall_7: 0.7000 - val_f1_score: 0.6907\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 20s 517ms/step - loss: 0.6533 - accuracy: 0.6511 - precision_7: 0.6506 - recall_7: 0.6528 - f1_score: 0.6330 - val_loss: 0.6471 - val_accuracy: 0.6900 - val_precision_7: 0.7045 - val_recall_7: 0.6833 - val_f1_score: 0.6808\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 19s 512ms/step - loss: 0.6526 - accuracy: 0.6436 - precision_7: 0.6438 - recall_7: 0.6260 - f1_score: 0.6332 - val_loss: 0.6457 - val_accuracy: 0.6933 - val_precision_7: 0.7013 - val_recall_7: 0.6967 - val_f1_score: 0.6925\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.6505 - accuracy: 0.6640 - precision_7: 0.6778 - recall_7: 0.6507 - f1_score: 0.6617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.650529146194458,\n",
       " 0.6639999747276306,\n",
       " 0.6777777671813965,\n",
       " 0.6506666541099548,\n",
       " array([0.6337209, 0.6896551], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model10.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model10.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 512, 100)          40800     \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 256, 100)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                256010    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 296,832\n",
      "Trainable params: 296,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM 100\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(X_train.shape[1], 1)))\n",
    "model.add(keras.layers.LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(keras.layers.Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=2)])\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 20s 466ms/step - loss: 0.6923 - accuracy: 0.5242 - precision_8: 0.5225 - recall_8: 0.5242 - f1_score: 0.4006 - val_loss: 0.6936 - val_accuracy: 0.4867 - val_precision_8: 0.4867 - val_recall_8: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 18s 477ms/step - loss: 0.6910 - accuracy: 0.5234 - precision_8: 0.5229 - recall_8: 0.5234 - f1_score: 0.3436 - val_loss: 0.6959 - val_accuracy: 0.4867 - val_precision_8: 0.4867 - val_recall_8: 0.4867 - val_f1_score: 0.3274\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 19s 495ms/step - loss: 0.6821 - accuracy: 0.5801 - precision_8: 0.5784 - recall_8: 0.4925 - f1_score: 0.5514 - val_loss: 0.6599 - val_accuracy: 0.6400 - val_precision_8: 0.6592 - val_recall_8: 0.4900 - val_f1_score: 0.6270\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 19s 498ms/step - loss: 0.6654 - accuracy: 0.5960 - precision_8: 0.5974 - recall_8: 0.5835 - f1_score: 0.5913 - val_loss: 0.6356 - val_accuracy: 0.6767 - val_precision_8: 0.6773 - val_recall_8: 0.6367 - val_f1_score: 0.6563\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 19s 502ms/step - loss: 0.6394 - accuracy: 0.6361 - precision_8: 0.6395 - recall_8: 0.6411 - f1_score: 0.6310 - val_loss: 0.5964 - val_accuracy: 0.6800 - val_precision_8: 0.6791 - val_recall_8: 0.6700 - val_f1_score: 0.6716\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 19s 506ms/step - loss: 0.6426 - accuracy: 0.6361 - precision_8: 0.6346 - recall_8: 0.6377 - f1_score: 0.6321 - val_loss: 0.5905 - val_accuracy: 0.7033 - val_precision_8: 0.6916 - val_recall_8: 0.7100 - val_f1_score: 0.7019\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 19s 500ms/step - loss: 0.6267 - accuracy: 0.6553 - precision_8: 0.6498 - recall_8: 0.6628 - f1_score: 0.6527 - val_loss: 0.5776 - val_accuracy: 0.7033 - val_precision_8: 0.7019 - val_recall_8: 0.7300 - val_f1_score: 0.7031\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 19s 493ms/step - loss: 0.6180 - accuracy: 0.6619 - precision_8: 0.6628 - recall_8: 0.6611 - f1_score: 0.6597 - val_loss: 0.5654 - val_accuracy: 0.7133 - val_precision_8: 0.7124 - val_recall_8: 0.7100 - val_f1_score: 0.7131\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 19s 496ms/step - loss: 0.5921 - accuracy: 0.6970 - precision_8: 0.6953 - recall_8: 0.6953 - f1_score: 0.6951 - val_loss: 0.5698 - val_accuracy: 0.7400 - val_precision_8: 0.7417 - val_recall_8: 0.7467 - val_f1_score: 0.7348\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 19s 499ms/step - loss: 0.6069 - accuracy: 0.6786 - precision_8: 0.6799 - recall_8: 0.6845 - f1_score: 0.6758 - val_loss: 0.5614 - val_accuracy: 0.7267 - val_precision_8: 0.7192 - val_recall_8: 0.7600 - val_f1_score: 0.7257\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.6032 - accuracy: 0.6693 - precision_8: 0.6582 - recall_8: 0.6880 - f1_score: 0.6668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.603188157081604,\n",
       " 0.6693333387374878,\n",
       " 0.6581632494926453,\n",
       " 0.6880000233650208,\n",
       " array([0.63742685, 0.6960784 ], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model10.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model10.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
