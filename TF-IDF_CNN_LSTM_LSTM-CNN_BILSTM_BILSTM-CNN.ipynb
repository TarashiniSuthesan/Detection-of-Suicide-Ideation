{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling1D, Dropout, Conv1D, Input, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined-selftext.csv')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_join(df, sep, *cols):\n",
    "   ...:     from functools import reduce\n",
    "   ...:     return reduce(lambda x, y: x.astype(str).str.cat(y.astype(str), sep=sep), \n",
    "   ...:                   [df[col] for col in cols])\n",
    "   ...: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = str_join(df,\" \", 'title', 'usertext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['title']\n",
    "del df['usertext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "STOPWORDS = STOPWORDS.union(set(['im', 'ive', 'ill', 'wa', 'ha', 'aint', 'thats', 'la', 'le', 'please', 'feel', 'rly', 'u', 'nan', 'emptypost']))\n",
    "\n",
    "stop = STOPWORDS\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>text</th>\n",
       "      <th>text_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[need, help, hi, know, phrase, situation, try,...</td>\n",
       "      <td>need help hi know phrase situation try life go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[feeling, overwhelmed, hopeless, depressed, pa...</td>\n",
       "      <td>feeling overwhelmed hopeless depressed past co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[matter, anymore, getting, worse, hi, know, de...</td>\n",
       "      <td>matter anymore getting worse hi know devastate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[tired, hearing, bullshit, shit, like, better,...</td>\n",
       "      <td>tired hearing bullshit shit like better purpos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[wish, wish, prettier, wish, like, burden, wis...</td>\n",
       "      <td>wish wish prettier wish like burden wish broke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y                                               text  \\\n",
       "0  0  [need, help, hi, know, phrase, situation, try,...   \n",
       "1  1  [feeling, overwhelmed, hopeless, depressed, pa...   \n",
       "2  0  [matter, anymore, getting, worse, hi, know, de...   \n",
       "3  1  [tired, hearing, bullshit, shit, like, better,...   \n",
       "4  0  [wish, wish, prettier, wish, like, burden, wis...   \n",
       "\n",
       "                                       text_original  \n",
       "0  need help hi know phrase situation try life go...  \n",
       "1  feeling overwhelmed hopeless depressed past co...  \n",
       "2  matter anymore getting worse hi know devastate...  \n",
       "3  tired hearing bullshit shit like better purpos...  \n",
       "4  wish wish prettier wish like burden wish broke...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].dropna(inplace=True)\n",
    "# 2. Changing all text to lowercase\n",
    "df['text_original'] = df['text']\n",
    "df['text'] = [entry.lower() for entry in df['text']]\n",
    "# 3. Tokenization-In this each entry in the corpus will be broken into set of words\n",
    "df['text']= [word_tokenize(entry) for entry in df['text']]\n",
    "# 4. Remove Stop words, Non-Numeric and perfoming Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>text</th>\n",
       "      <th>text_original</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[need, help, hi, know, phrase, situation, try,...</td>\n",
       "      <td>need help hi know phrase situation try life go...</td>\n",
       "      <td>['need', 'help', 'hi', 'know', 'phrase', 'situ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[feeling, overwhelmed, hopeless, depressed, pa...</td>\n",
       "      <td>feeling overwhelmed hopeless depressed past co...</td>\n",
       "      <td>['feel', 'overwhelmed', 'hopeless', 'depress',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[matter, anymore, getting, worse, hi, know, de...</td>\n",
       "      <td>matter anymore getting worse hi know devastate...</td>\n",
       "      <td>['matter', 'anymore', 'get', 'bad', 'hi', 'kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[tired, hearing, bullshit, shit, like, better,...</td>\n",
       "      <td>tired hearing bullshit shit like better purpos...</td>\n",
       "      <td>['tired', 'hearing', 'bullshit', 'shit', 'like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[wish, wish, prettier, wish, like, burden, wis...</td>\n",
       "      <td>wish wish prettier wish like burden wish broke...</td>\n",
       "      <td>['wish', 'wish', 'prettier', 'wish', 'like', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y                                               text  \\\n",
       "0  0  [need, help, hi, know, phrase, situation, try,...   \n",
       "1  1  [feeling, overwhelmed, hopeless, depressed, pa...   \n",
       "2  0  [matter, anymore, getting, worse, hi, know, de...   \n",
       "3  1  [tired, hearing, bullshit, shit, like, better,...   \n",
       "4  0  [wish, wish, prettier, wish, like, burden, wis...   \n",
       "\n",
       "                                       text_original  \\\n",
       "0  need help hi know phrase situation try life go...   \n",
       "1  feeling overwhelmed hopeless depressed past co...   \n",
       "2  matter anymore getting worse hi know devastate...   \n",
       "3  tired hearing bullshit shit like better purpos...   \n",
       "4  wish wish prettier wish like burden wish broke...   \n",
       "\n",
       "                                          text_final  \n",
       "0  ['need', 'help', 'hi', 'know', 'phrase', 'situ...  \n",
       "1  ['feel', 'overwhelmed', 'hopeless', 'depress',...  \n",
       "2  ['matter', 'anymore', 'get', 'bad', 'hi', 'kno...  \n",
       "3  ['tired', 'hearing', 'bullshit', 'shit', 'like...  \n",
       "4  ['wish', 'wish', 'prettier', 'wish', 'like', '...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index,entry in enumerate(df['text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    df.loc[index,'text_final'] = str(Final_words)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df['text_final'],df['y'],test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(df['text_final'])\n",
    "X_train = Tfidf_vect.transform(X_train)\n",
    "X_test = Tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.todense()\n",
    "X_test = X_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 8548) (375, 8548)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498,) (375,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1498"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8547"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 8548, 5)           15        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8548, 5)           0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 42740)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                2735424   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,735,504\n",
      "Trainable params: 2,735,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "\n",
    "model4 = keras.Sequential()\n",
    "\n",
    "model4.add(keras.layers.Input(shape=(X_train.shape[1], 1)))\n",
    "model4.add(keras.layers.Conv1D(5, (2,), padding='same', activation='relu'))\n",
    "model4.add(keras.layers.Dropout(0.5))\n",
    "model4.add(keras.layers.Flatten())\n",
    "model4.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model4.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model4.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 3s 48ms/step - loss: 0.6891 - accuracy: 0.5417 - precision: 0.5334 - recall: 0.9373 - f1_score: 0.6835 - val_loss: 0.6759 - val_accuracy: 0.6100 - val_precision: 0.5893 - val_recall: 0.9880 - val_f1_score: 0.7152\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.6394 - accuracy: 0.7396 - precision: 0.6726 - recall: 0.9711 - f1_score: 0.6835 - val_loss: 0.6356 - val_accuracy: 0.6800 - val_precision: 0.6449 - val_recall: 0.9461 - val_f1_score: 0.7152\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5230 - accuracy: 0.8314 - precision: 0.8035 - recall: 0.8939 - f1_score: 0.6835 - val_loss: 0.6025 - val_accuracy: 0.7067 - val_precision: 0.8496 - val_recall: 0.5749 - val_f1_score: 0.7152\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.3996 - accuracy: 0.8781 - precision: 0.8790 - recall: 0.8875 - f1_score: 0.6835 - val_loss: 0.5550 - val_accuracy: 0.7567 - val_precision: 0.7527 - val_recall: 0.8383 - val_f1_score: 0.7152\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.2913 - accuracy: 0.9265 - precision: 0.9265 - recall: 0.9325 - f1_score: 0.6835 - val_loss: 0.5514 - val_accuracy: 0.7467 - val_precision: 0.7486 - val_recall: 0.8204 - val_f1_score: 0.7152\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.2206 - accuracy: 0.9432 - precision: 0.9355 - recall: 0.9566 - f1_score: 0.6835 - val_loss: 0.5754 - val_accuracy: 0.7300 - val_precision: 0.7529 - val_recall: 0.7665 - val_f1_score: 0.7152\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.1627 - accuracy: 0.9616 - precision: 0.9571 - recall: 0.9695 - f1_score: 0.6835 - val_loss: 0.6011 - val_accuracy: 0.7067 - val_precision: 0.7207 - val_recall: 0.7725 - val_f1_score: 0.7152\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.1442 - accuracy: 0.9649 - precision: 0.9545 - recall: 0.9791 - f1_score: 0.6835 - val_loss: 0.6656 - val_accuracy: 0.6833 - val_precision: 0.7571 - val_recall: 0.6347 - val_f1_score: 0.7152\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.1084 - accuracy: 0.9733 - precision: 0.9743 - recall: 0.9743 - f1_score: 0.6835 - val_loss: 0.6627 - val_accuracy: 0.6633 - val_precision: 0.6793 - val_recall: 0.7485 - val_f1_score: 0.7152\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.0984 - accuracy: 0.9791 - precision: 0.9746 - recall: 0.9855 - f1_score: 0.6835 - val_loss: 0.7116 - val_accuracy: 0.6733 - val_precision: 0.7041 - val_recall: 0.7126 - val_f1_score: 0.7152\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8153 - accuracy: 0.6373 - precision: 0.6062 - recall: 0.6610 - f1_score: 0.6413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8153498768806458,\n",
       " 0.637333333492279,\n",
       " 0.606217622756958,\n",
       " 0.6610169410705566,\n",
       " array([0.6413044], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history4 = model4.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 8548, 100)         40800     \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 4274, 100)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 427400)            0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                27353664  \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,394,529\n",
      "Trainable params: 27,394,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "\n",
    "model6 = keras.Sequential()\n",
    "\n",
    "model6.add(keras.layers.Input(shape=(X_train.shape[1], 1)))\n",
    "model6.add(keras.layers.LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "model6.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model6.add(keras.layers.Flatten())\n",
    "model6.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model6.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model6.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 1004s 27s/step - loss: 0.7176 - accuracy: 0.5017 - precision_1: 0.5179 - recall_1: 0.5820 - f1_score: 0.6835 - val_loss: 0.6909 - val_accuracy: 0.6333 - val_precision_1: 0.6100 - val_recall_1: 0.9461 - val_f1_score: 0.7152\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 1119s 29s/step - loss: 0.6948 - accuracy: 0.5209 - precision_1: 0.5303 - recall_1: 0.6752 - f1_score: 0.6835 - val_loss: 0.6829 - val_accuracy: 0.5567 - val_precision_1: 0.5567 - val_recall_1: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 1189s 31s/step - loss: 0.7070 - accuracy: 0.5117 - precision_1: 0.5284 - recall_1: 0.5531 - f1_score: 0.6835 - val_loss: 0.6797 - val_accuracy: 0.7000 - val_precision_1: 0.7484 - val_recall_1: 0.6946 - val_f1_score: 0.7152\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 1221s 32s/step - loss: 0.6656 - accuracy: 0.5918 - precision_1: 0.5933 - recall_1: 0.6801 - f1_score: 0.6835 - val_loss: 0.6315 - val_accuracy: 0.6700 - val_precision_1: 0.7833 - val_recall_1: 0.5629 - val_f1_score: 0.7152\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 1192s 31s/step - loss: 0.6059 - accuracy: 0.6711 - precision_1: 0.6717 - recall_1: 0.7170 - f1_score: 0.6835 - val_loss: 0.6398 - val_accuracy: 0.6033 - val_precision_1: 0.5845 - val_recall_1: 0.9940 - val_f1_score: 0.7152\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 1255s 33s/step - loss: 0.5651 - accuracy: 0.7062 - precision_1: 0.7157 - recall_1: 0.7203 - f1_score: 0.6835 - val_loss: 0.6215 - val_accuracy: 0.6733 - val_precision_1: 0.8286 - val_recall_1: 0.5210 - val_f1_score: 0.7152\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 1238s 33s/step - loss: 0.5368 - accuracy: 0.7329 - precision_1: 0.7484 - recall_1: 0.7315 - f1_score: 0.6835 - val_loss: 0.5813 - val_accuracy: 0.6900 - val_precision_1: 0.7033 - val_recall_1: 0.7665 - val_f1_score: 0.7152\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 1248s 33s/step - loss: 0.4877 - accuracy: 0.7646 - precision_1: 0.7690 - recall_1: 0.7814 - f1_score: 0.6835 - val_loss: 0.5803 - val_accuracy: 0.6833 - val_precision_1: 0.6856 - val_recall_1: 0.7964 - val_f1_score: 0.7152\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 1270s 33s/step - loss: 0.4369 - accuracy: 0.8114 - precision_1: 0.8143 - recall_1: 0.8248 - f1_score: 0.6835 - val_loss: 0.6000 - val_accuracy: 0.7067 - val_precision_1: 0.8110 - val_recall_1: 0.6168 - val_f1_score: 0.7152\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 1325s 35s/step - loss: 0.4017 - accuracy: 0.8230 - precision_1: 0.8285 - recall_1: 0.8312 - f1_score: 0.6835 - val_loss: 0.6110 - val_accuracy: 0.6933 - val_precision_1: 0.7863 - val_recall_1: 0.6168 - val_f1_score: 0.7152\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6473 - accuracy: 0.6293 - precision_1: 0.6145 - recall_1: 0.5763 - f1_score: 0.6413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6473361849784851,\n",
       " 0.6293333172798157,\n",
       " 0.6144578456878662,\n",
       " 0.5762711763381958,\n",
       " array([0.6413044], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history6 = model6.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model6.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 8548, 100)         40800     \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 8548, 5)           1005      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 4274, 5)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 21370)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                1367744   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,409,614\n",
      "Trainable params: 1,409,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM + CNN\n",
    "\n",
    "model7 = keras.Sequential()\n",
    "\n",
    "model7.add(keras.layers.Input(shape=(X_train.shape[1], 1)))\n",
    "model7.add(keras.layers.LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "model7.add(keras.layers.Conv1D(5, (2,), padding='same', activation='relu'))\n",
    "model7.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model7.add(keras.layers.Flatten())\n",
    "model7.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model7.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model7.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 1378s 36s/step - loss: 0.6934 - accuracy: 0.5192 - precision_2: 0.5193 - recall_2: 0.9968 - f1_score: 0.6835 - val_loss: 0.6922 - val_accuracy: 0.5567 - val_precision_2: 0.5567 - val_recall_2: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 1481s 39s/step - loss: 0.6907 - accuracy: 0.5451 - precision_2: 0.5350 - recall_2: 0.9469 - f1_score: 0.6835 - val_loss: 0.6897 - val_accuracy: 0.5567 - val_precision_2: 0.5567 - val_recall_2: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 1499s 39s/step - loss: 0.6638 - accuracy: 0.6361 - precision_2: 0.5996 - recall_2: 0.9003 - f1_score: 0.6835 - val_loss: 0.6431 - val_accuracy: 0.6700 - val_precision_2: 0.7073 - val_recall_2: 0.6946 - val_f1_score: 0.7152\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 1498s 39s/step - loss: 0.6230 - accuracy: 0.6895 - precision_2: 0.6806 - recall_2: 0.7572 - f1_score: 0.6835 - val_loss: 0.6479 - val_accuracy: 0.6167 - val_precision_2: 0.5977 - val_recall_2: 0.9521 - val_f1_score: 0.7152\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 1465s 39s/step - loss: 0.5419 - accuracy: 0.7387 - precision_2: 0.6978 - recall_2: 0.8762 - f1_score: 0.6835 - val_loss: 0.6032 - val_accuracy: 0.6833 - val_precision_2: 0.7571 - val_recall_2: 0.6347 - val_f1_score: 0.7152\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 1474s 39s/step - loss: 0.4913 - accuracy: 0.7696 - precision_2: 0.7883 - recall_2: 0.7605 - f1_score: 0.6835 - val_loss: 0.6020 - val_accuracy: 0.6667 - val_precision_2: 0.7481 - val_recall_2: 0.6048 - val_f1_score: 0.7152\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 1568s 41s/step - loss: 0.4552 - accuracy: 0.7880 - precision_2: 0.8077 - recall_2: 0.7765 - f1_score: 0.6835 - val_loss: 0.6002 - val_accuracy: 0.6733 - val_precision_2: 0.7255 - val_recall_2: 0.6647 - val_f1_score: 0.7152\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 3353s 88s/step - loss: 0.4151 - accuracy: 0.8114 - precision_2: 0.8163 - recall_2: 0.8215 - f1_score: 0.6835 - val_loss: 0.6054 - val_accuracy: 0.6667 - val_precision_2: 0.7343 - val_recall_2: 0.6287 - val_f1_score: 0.7152\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 1594s 42s/step - loss: 0.3859 - accuracy: 0.8205 - precision_2: 0.8375 - recall_2: 0.8119 - f1_score: 0.6835 - val_loss: 0.6118 - val_accuracy: 0.6700 - val_precision_2: 0.7267 - val_recall_2: 0.6527 - val_f1_score: 0.7152\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 1607s 42s/step - loss: 0.3920 - accuracy: 0.8139 - precision_2: 0.8364 - recall_2: 0.7974 - f1_score: 0.6835 - val_loss: 0.6257 - val_accuracy: 0.6567 - val_precision_2: 0.7105 - val_recall_2: 0.6467 - val_f1_score: 0.7152\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.6935 - accuracy: 0.6427 - precision_2: 0.6175 - recall_2: 0.6384 - f1_score: 0.6413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6935282945632935,\n",
       " 0.6426666378974915,\n",
       " 0.6174863576889038,\n",
       " 0.6384180784225464,\n",
       " array([0.6413044], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history7 = model7.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model7.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 8548, 200)        81600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 4274, 200)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 854800)            0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                54707264  \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,788,929\n",
      "Trainable params: 54,788,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM\n",
    "\n",
    "model8 = keras.Sequential()\n",
    "\n",
    "model8.add(keras.layers.Input(shape=(X_train.shape[1], 1)))\n",
    "model8.add(keras.layers.Bidirectional(LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)))\n",
    "model8.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model8.add(keras.layers.Flatten())\n",
    "model8.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model8.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model8.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 3723s 98s/step - loss: 0.7027 - accuracy: 0.5200 - precision: 0.5217 - recall: 0.9084 - f1_score: 0.6835 - val_loss: 0.6926 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 3928s 103s/step - loss: 0.6929 - accuracy: 0.5192 - precision: 0.5192 - recall: 1.0000 - f1_score: 0.6835 - val_loss: 0.6924 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 4090s 108s/step - loss: 0.6929 - accuracy: 0.5192 - precision: 0.5192 - recall: 1.0000 - f1_score: 0.6835 - val_loss: 0.6920 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 4374s 115s/step - loss: 0.6928 - accuracy: 0.5192 - precision: 0.5192 - recall: 1.0000 - f1_score: 0.6835 - val_loss: 0.6917 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 4410s 116s/step - loss: 0.6928 - accuracy: 0.5192 - precision: 0.5192 - recall: 1.0000 - f1_score: 0.6835 - val_loss: 0.6914 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 7140s 190s/step - loss: 0.6927 - accuracy: 0.5192 - precision: 0.5192 - recall: 1.0000 - f1_score: 0.6835 - val_loss: 0.6914 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 4365s 115s/step - loss: 0.6926 - accuracy: 0.5192 - precision: 0.5192 - recall: 1.0000 - f1_score: 0.6835 - val_loss: 0.6911 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 6185s 164s/step - loss: 0.6926 - accuracy: 0.5192 - precision: 0.5192 - recall: 1.0000 - f1_score: 0.6835 - val_loss: 0.6910 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 4469s 118s/step - loss: 0.6926 - accuracy: 0.5192 - precision: 0.5192 - recall: 1.0000 - f1_score: 0.6835 - val_loss: 0.6908 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 4541s 120s/step - loss: 0.6925 - accuracy: 0.5192 - precision: 0.5192 - recall: 1.0000 - f1_score: 0.6835 - val_loss: 0.6907 - val_accuracy: 0.5567 - val_precision: 0.5567 - val_recall: 1.0000 - val_f1_score: 0.7152\n",
      "12/12 [==============================] - 40s 3s/step - loss: 0.6948 - accuracy: 0.4720 - precision: 0.4720 - recall: 1.0000 - f1_score: 0.6413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6947916150093079,\n",
       " 0.47200000286102295,\n",
       " 0.47200000286102295,\n",
       " 1.0,\n",
       " array([0.6413044], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history8 = model8.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model8.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirectio  (None, 8548, 200)        81600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 8548, 5)           2005      \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 4274, 5)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 21370)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                1367744   \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,451,414\n",
      "Trainable params: 1,451,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BiLSTM + CNN\n",
    "\n",
    "model9 = keras.Sequential()\n",
    "\n",
    "model9.add(keras.layers.Input(shape=(X_train.shape[1], 1)))\n",
    "model9.add(keras.layers.Bidirectional(LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)))\n",
    "model9.add(keras.layers.Conv1D(5, (2,), padding='same', activation='relu'))\n",
    "model9.add(keras.layers.MaxPooling1D(pool_size = 2))\n",
    "model9.add(keras.layers.Flatten())\n",
    "model9.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model9.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model9.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 4755s 125s/step - loss: 0.6941 - accuracy: 0.5125 - precision_1: 0.5312 - recall_1: 0.5193 - f1_score: 0.6835 - val_loss: 0.6928 - val_accuracy: 0.5567 - val_precision_1: 0.5567 - val_recall_1: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 7128s 142s/step - loss: 0.6932 - accuracy: 0.5175 - precision_1: 0.5193 - recall_1: 0.9502 - f1_score: 0.6835 - val_loss: 0.6922 - val_accuracy: 0.5567 - val_precision_1: 0.5567 - val_recall_1: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 5144s 135s/step - loss: 0.6915 - accuracy: 0.5351 - precision_1: 0.5277 - recall_1: 0.9968 - f1_score: 0.6835 - val_loss: 0.6917 - val_accuracy: 0.5633 - val_precision_1: 0.5604 - val_recall_1: 1.0000 - val_f1_score: 0.7152\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 5015s 132s/step - loss: 0.6826 - accuracy: 0.6611 - precision_1: 0.6224 - recall_1: 0.8826 - f1_score: 0.6835 - val_loss: 0.6796 - val_accuracy: 0.6333 - val_precision_1: 0.6100 - val_recall_1: 0.9461 - val_f1_score: 0.7152\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 5147s 135s/step - loss: 0.6452 - accuracy: 0.7437 - precision_1: 0.7320 - recall_1: 0.7990 - f1_score: 0.6835 - val_loss: 0.6336 - val_accuracy: 0.6767 - val_precision_1: 0.7574 - val_recall_1: 0.6168 - val_f1_score: 0.7152\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 5287s 139s/step - loss: 0.4922 - accuracy: 0.8356 - precision_1: 0.8559 - recall_1: 0.8215 - f1_score: 0.6835 - val_loss: 0.5788 - val_accuracy: 0.6767 - val_precision_1: 0.7188 - val_recall_1: 0.6886 - val_f1_score: 0.7152\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 5310s 140s/step - loss: 0.3345 - accuracy: 0.8740 - precision_1: 0.8720 - recall_1: 0.8875 - f1_score: 0.6835 - val_loss: 0.5987 - val_accuracy: 0.6867 - val_precision_1: 0.7355 - val_recall_1: 0.6826 - val_f1_score: 0.7152\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 6229s 164s/step - loss: 0.2464 - accuracy: 0.9015 - precision_1: 0.9065 - recall_1: 0.9035 - f1_score: 0.6835 - val_loss: 0.6599 - val_accuracy: 0.7033 - val_precision_1: 0.7566 - val_recall_1: 0.6886 - val_f1_score: 0.7152\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 5112s 134s/step - loss: 0.1668 - accuracy: 0.9491 - precision_1: 0.9403 - recall_1: 0.9630 - f1_score: 0.6835 - val_loss: 0.7827 - val_accuracy: 0.6767 - val_precision_1: 0.7273 - val_recall_1: 0.6707 - val_f1_score: 0.7152\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 5108s 134s/step - loss: 0.1057 - accuracy: 0.9649 - precision_1: 0.9633 - recall_1: 0.9695 - f1_score: 0.6835 - val_loss: 0.8794 - val_accuracy: 0.6700 - val_precision_1: 0.7152 - val_recall_1: 0.6766 - val_f1_score: 0.7152\n",
      "12/12 [==============================] - 48s 4s/step - loss: 1.0351 - accuracy: 0.6347 - precision_1: 0.6099 - recall_1: 0.6271 - f1_score: 0.6413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.035083293914795,\n",
       " 0.6346666812896729,\n",
       " 0.6098901033401489,\n",
       " 0.6271186470985413,\n",
       " array([0.6413044], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history9 = model9.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model9.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
