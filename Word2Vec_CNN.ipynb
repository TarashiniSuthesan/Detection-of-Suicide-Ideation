{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling1D, Dropout, Conv1D, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined-selftext.csv')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def str_join(df, sep, *cols):\n",
    "   ...:     from functools import reduce\n",
    "   ...:     return reduce(lambda x, y: x.astype(str).str.cat(y.astype(str), sep=sep), \n",
    "   ...:                   [df[col] for col in cols])\n",
    "   ...: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['text'] = str_join(df,\" \", 'title', 'usertext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['text'] = str_join(df,\" \", 'title', 'usertext')\n",
    "del df['title']\n",
    "del df['usertext']\n",
    "df.rename(columns = {'y':'is_suicide'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].apply(lambda x: gensim.utils.simple_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text_clean'], df['is_suicide'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(df['text_clean'],\n",
    "                                   vector_size=300,\n",
    "                                   epochs=20,\n",
    "                                   window=10,\n",
    "                                   min_count=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a03581770919>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
      "<ipython-input-10-a03581770919>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n"
     ]
    }
   ],
   "source": [
    "words = set(w2v_model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_train])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(300, dtype=float))\n",
    "        \n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(300, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train_vect_avg)\n",
    "X_test = np.array(X_test_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 300) (375, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498,) (375,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1498"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 300, 5)            15        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300, 5)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                96064     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,144\n",
      "Trainable params: 96,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = keras.Sequential()\n",
    "\n",
    "model4.add(keras.layers.Input(shape=(300, 1)))\n",
    "model4.add(keras.layers.Conv1D(5, (2,), padding='same', activation='relu'))\n",
    "model4.add(keras.layers.Dropout(0.5))\n",
    "model4.add(keras.layers.Flatten())\n",
    "model4.add(keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model4.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model4.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy',\n",
    "                              tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall(),\n",
    "                              tfa.metrics.F1Score(num_classes=1)])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.6515 - accuracy: 0.6302 - precision_2: 0.6409 - recall_2: 0.6440 - f1_score: 0.6806 - val_loss: 0.6380 - val_accuracy: 0.6200 - val_precision_2: 0.6552 - val_recall_2: 0.5975 - val_f1_score: 0.6928\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.6644 - precision_2: 0.6736 - recall_2: 0.6780 - f1_score: 0.6806 - val_loss: 0.6385 - val_accuracy: 0.6400 - val_precision_2: 0.6321 - val_recall_2: 0.7673 - val_f1_score: 0.6928\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6636 - precision_2: 0.6646 - recall_2: 0.7023 - f1_score: 0.6806 - val_loss: 0.6353 - val_accuracy: 0.6433 - val_precision_2: 0.6444 - val_recall_2: 0.7296 - val_f1_score: 0.6928\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6611 - precision_2: 0.6667 - recall_2: 0.6861 - f1_score: 0.6806 - val_loss: 0.6371 - val_accuracy: 0.6267 - val_precision_2: 0.6497 - val_recall_2: 0.6415 - val_f1_score: 0.6928\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.6761 - precision_2: 0.6737 - recall_2: 0.7217 - f1_score: 0.6806 - val_loss: 0.6341 - val_accuracy: 0.6233 - val_precision_2: 0.6402 - val_recall_2: 0.6604 - val_f1_score: 0.6928\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.6703 - precision_2: 0.6628 - recall_2: 0.7346 - f1_score: 0.6806 - val_loss: 0.6333 - val_accuracy: 0.6433 - val_precision_2: 0.6566 - val_recall_2: 0.6855 - val_f1_score: 0.6928\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.6861 - precision_2: 0.7058 - recall_2: 0.6715 - f1_score: 0.6806 - val_loss: 0.6386 - val_accuracy: 0.6400 - val_precision_2: 0.6281 - val_recall_2: 0.7862 - val_f1_score: 0.6928\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.6853 - precision_2: 0.6880 - recall_2: 0.7136 - f1_score: 0.6806 - val_loss: 0.6448 - val_accuracy: 0.6233 - val_precision_2: 0.6117 - val_recall_2: 0.7925 - val_f1_score: 0.6928\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.6928 - precision_2: 0.6866 - recall_2: 0.7443 - f1_score: 0.6806 - val_loss: 0.6400 - val_accuracy: 0.6400 - val_precision_2: 0.6364 - val_recall_2: 0.7484 - val_f1_score: 0.6928\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.6920 - precision_2: 0.6872 - recall_2: 0.7395 - f1_score: 0.6806 - val_loss: 0.6482 - val_accuracy: 0.6200 - val_precision_2: 0.6642 - val_recall_2: 0.5723 - val_f1_score: 0.6928\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7120 - precision_2: 0.7425 - recall_2: 0.6561 - f1_score: 0.6702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5697172284126282,\n",
       " 0.7120000123977661,\n",
       " 0.742514967918396,\n",
       " 0.6560846567153931,\n",
       " array([0.6702128], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history4 = model4.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    ")\n",
    "model4.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
